{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-10T19:51:57.365436Z","iopub.status.busy":"2024-03-10T19:51:57.365048Z","iopub.status.idle":"2024-03-10T19:51:57.372856Z","shell.execute_reply":"2024-03-10T19:51:57.371630Z","shell.execute_reply.started":"2024-03-10T19:51:57.365407Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\divij\\AppData\\Local\\Temp\\ipykernel_45192\\2009171990.py:3: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"]}],"source":["import os\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import datetime\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from sklearn import preprocessing\n","dataset = \"\"\"C:\\\\Users\\\\divij\\\\Desktop\\\\ml\\\\project\\\\dataset\"\"\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:50:27.625379Z","iopub.status.busy":"2024-03-10T19:50:27.624982Z","iopub.status.idle":"2024-03-10T19:50:27.642482Z","shell.execute_reply":"2024-03-10T19:50:27.641296Z","shell.execute_reply.started":"2024-03-10T19:50:27.625347Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  0\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, Flatten, Dropout\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator \n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"markdown","metadata":{},"source":["This Project is Divided Into 3 section Data Cleaning and Pre Processing"]},{"cell_type":"markdown","metadata":{},"source":["Section 1 : Data PreProcessing "]},{"cell_type":"markdown","metadata":{},"source":["Check if GPU is Available"]},{"cell_type":"markdown","metadata":{},"source":["SECTION 1.1 : Seting Up DataFrames"]},{"cell_type":"markdown","metadata":{},"source":["### Setup Dataset"]},{"cell_type":"markdown","metadata":{},"source":["Train Dataframe"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:49:30.063033Z","iopub.status.busy":"2024-03-10T19:49:30.062688Z","iopub.status.idle":"2024-03-10T19:49:53.516289Z","shell.execute_reply":"2024-03-10T19:49:53.515382Z","shell.execute_reply.started":"2024-03-10T19:49:30.063001Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of df_train is:  (84635, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                path            label\n","0  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","1  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","2  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","3  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","4  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","5  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","6  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","7  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","8  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER\n","9  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\trai...  ABBOTTS BABBLER"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["paths = []\n","labels = []\n","for bird_type in os.listdir(dataset+\"\\\\train\"):\n","    cur_path = os.path.join(dataset+\"\\\\train\",bird_type)\n","    path_data = os.listdir(cur_path)\n","    paths.extend([os.path.join(cur_path,img) for img in path_data])\n","    labels.extend([bird_type]*len(path_data))\n","\n","df_train = pd.DataFrame({\"path\":paths,\"label\":labels})\n","\n","print(\"Shape of df_train is: \", df_train.shape)\n","df_train.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["Validation DataFrame"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:49:53.519301Z","iopub.status.busy":"2024-03-10T19:49:53.518823Z","iopub.status.idle":"2024-03-10T19:49:56.000342Z","shell.execute_reply":"2024-03-10T19:49:55.999449Z","shell.execute_reply.started":"2024-03-10T19:49:53.519273Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of df_valid is:  (2625, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                path            label\n","0  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...  ABBOTTS BABBLER\n","1  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...  ABBOTTS BABBLER\n","2  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...  ABBOTTS BABBLER\n","3  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...  ABBOTTS BABBLER\n","4  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...  ABBOTTS BABBLER\n","5  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...    ABBOTTS BOOBY\n","6  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...    ABBOTTS BOOBY\n","7  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...    ABBOTTS BOOBY\n","8  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...    ABBOTTS BOOBY\n","9  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\vali...    ABBOTTS BOOBY"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["paths = []\n","labels = []\n","for bird_type in os.listdir(dataset+\"\\\\valid\"):\n","    cur_path = os.path.join(dataset+\"\\\\valid\",bird_type)\n","    path_data = os.listdir(cur_path)\n","    paths.extend([os.path.join(cur_path,img) for img in path_data])\n","    labels.extend([bird_type]*len(path_data))\n","\n","df_valid = pd.DataFrame({\"path\":paths,\"label\":labels})\n","\n","print(\"Shape of df_valid is: \", df_valid.shape)\n","df_valid.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["Test Dataframe"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:49:56.002061Z","iopub.status.busy":"2024-03-10T19:49:56.001678Z","iopub.status.idle":"2024-03-10T19:49:58.609633Z","shell.execute_reply":"2024-03-10T19:49:58.608709Z","shell.execute_reply.started":"2024-03-10T19:49:56.002027Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of df_test is:  (2625, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BABBLER</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...</td>\n","      <td>ABBOTTS BOOBY</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                path            label\n","0  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...  ABBOTTS BABBLER\n","1  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...  ABBOTTS BABBLER\n","2  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...  ABBOTTS BABBLER\n","3  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...  ABBOTTS BABBLER\n","4  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...  ABBOTTS BABBLER\n","5  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...    ABBOTTS BOOBY\n","6  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...    ABBOTTS BOOBY\n","7  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...    ABBOTTS BOOBY\n","8  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...    ABBOTTS BOOBY\n","9  C:\\Users\\divij\\Desktop\\ml\\project\\dataset\\test...    ABBOTTS BOOBY"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["paths = []\n","labels = []\n","for bird_type in os.listdir(dataset+\"\\\\test\"):\n","    cur_path = os.path.join(dataset+\"\\\\test\",bird_type)\n","    path_data = os.listdir(cur_path)\n","    paths.extend([os.path.join(cur_path,img) for img in path_data])\n","    labels.extend([bird_type]*len(path_data))\n","\n","df_test = pd.DataFrame({\"path\":paths,\"label\":labels})\n","\n","print(\"Shape of df_test is: \", df_test.shape)\n","df_test.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["## Plots"]},{"cell_type":"markdown","metadata":{},"source":["No of Species of Brids are in the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:49:58.611221Z","iopub.status.busy":"2024-03-10T19:49:58.610934Z","iopub.status.idle":"2024-03-10T19:49:58.631144Z","shell.execute_reply":"2024-03-10T19:49:58.630004Z","shell.execute_reply.started":"2024-03-10T19:49:58.611198Z"},"trusted":true},"outputs":[],"source":["print(\"How many species of birds are there in dataset: \", df_train['label'].nunique())"]},{"cell_type":"markdown","metadata":{},"source":["No of Lables"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:49:58.632533Z","iopub.status.busy":"2024-03-10T19:49:58.632221Z","iopub.status.idle":"2024-03-10T19:49:58.658086Z","shell.execute_reply":"2024-03-10T19:49:58.657010Z","shell.execute_reply.started":"2024-03-10T19:49:58.632508Z"},"trusted":true},"outputs":[],"source":["df_train['label'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["Data Visualization Labels and Sample"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:49:58.660093Z","iopub.status.busy":"2024-03-10T19:49:58.659427Z","iopub.status.idle":"2024-03-10T19:50:04.401081Z","shell.execute_reply":"2024-03-10T19:50:04.400152Z","shell.execute_reply.started":"2024-03-10T19:49:58.660058Z"},"trusted":true},"outputs":[],"source":["labels = df_train['label']\n","label_counts = labels.value_counts()\n","\n","plt.figure(figsize=(18, 6))\n","sns.barplot(x=label_counts.index, y=label_counts.values)\n","plt.title('Class Distribution of trainset')\n","plt.xlabel('Class Labels')\n","plt.ylabel('Number of Samples')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:50:04.402738Z","iopub.status.busy":"2024-03-10T19:50:04.402336Z","iopub.status.idle":"2024-03-10T19:50:09.314988Z","shell.execute_reply":"2024-03-10T19:50:09.314046Z","shell.execute_reply.started":"2024-03-10T19:50:04.402714Z"},"trusted":true},"outputs":[],"source":["labels = df_valid['label']\n","label_counts = labels.value_counts()\n","\n","plt.figure(figsize=(18, 6))\n","sns.barplot(x=label_counts.index, y=label_counts.values)\n","plt.title('Class Distribution of validset')\n","plt.xlabel('Class Labels')\n","plt.ylabel('Number of Samples')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:50:09.319968Z","iopub.status.busy":"2024-03-10T19:50:09.319346Z","iopub.status.idle":"2024-03-10T19:50:14.382736Z","shell.execute_reply":"2024-03-10T19:50:14.381858Z","shell.execute_reply.started":"2024-03-10T19:50:09.319933Z"},"trusted":true},"outputs":[],"source":["labels = df_test['label']\n","label_counts = labels.value_counts()\n","\n","plt.figure(figsize=(18, 6))\n","sns.barplot(x=label_counts.index, y=label_counts.values)\n","plt.title('Class Distribution of testset')\n","plt.xlabel('Class Labels')\n","plt.ylabel('Number of Samples')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:50:14.406760Z","iopub.status.busy":"2024-03-10T19:50:14.406454Z","iopub.status.idle":"2024-03-10T19:50:27.266030Z","shell.execute_reply":"2024-03-10T19:50:27.265132Z","shell.execute_reply.started":"2024-03-10T19:50:14.406723Z"},"trusted":true},"outputs":[],"source":["# mapping data\n","le = preprocessing.LabelEncoder()\n","\n","df_train['label'] = df_train['label'].replace('PARAKETT  AUKLET', 'PARAKETT AUKLET')\n","df_test['label'] = df_test['label'].replace('PARAKETT  AUKLET', 'PARAKETT AUKLET')\n","\n","print(\"Shape of df_train is: \", df_train.shape)\n","print(\"Shape of df_valid is: \", df_valid.shape)\n","print(\"Shape of df_test is: \", df_test.shape)\n","\n","df_test.head(7)"]},{"cell_type":"markdown","metadata":{},"source":["View Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:50:27.267570Z","iopub.status.busy":"2024-03-10T19:50:27.267056Z","iopub.status.idle":"2024-03-10T19:50:27.273437Z","shell.execute_reply":"2024-03-10T19:50:27.272558Z","shell.execute_reply.started":"2024-03-10T19:50:27.267544Z"},"trusted":true},"outputs":[],"source":["def view_random_image(target_dir,target_class):\n","  # setting up the image directory\n","  target_folder = target_dir\n","\n","  #read image and plotting it\n","  img = mpimg.imread(target_folder)\n","  plt.imshow(img)\n","  plt.title(target_class)\n","  plt.axis(\"off\")\n","\n","  print(f\"Image shape: {img.shape}\")\n","  print(f\"Path : {target_folder}\")\n","  \n","  return img\n","\n","img = view_random_image(str(df_test['path'].values[99]), str(df_test['label'].values[99]))"]},{"cell_type":"markdown","metadata":{},"source":["## Defining Model"]},{"cell_type":"markdown","metadata":{},"source":["Classification Model: "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T19:50:28.723387Z","iopub.status.busy":"2024-03-10T19:50:28.723079Z","iopub.status.idle":"2024-03-10T19:50:28.838545Z","shell.execute_reply":"2024-03-10T19:50:28.837671Z","shell.execute_reply.started":"2024-03-10T19:50:28.723362Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\divij\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">22,151,424</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">134,925</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m22,151,424\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m525\u001b[0m)            │       \u001b[38;5;34m134,925\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,379,597</span> (85.37 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,379,597\u001b[0m (85.37 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,379,597</span> (85.37 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,379,597\u001b[0m (85.37 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Define the model\n","model = Sequential()\n","\n","# Convolutional layers with max pooling\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n","model.add(MaxPooling2D((2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","# Flatten the output to feed into dense layers\n","model.add(Flatten())\n","\n","# Dense (fully connected) layers\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n","\n","# Output layer with softmax activation for classification\n","model.add(Dense(525, activation='softmax'))\n","\n","# Print the model summary\n","model.summary()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 84635 images belonging to 525 classes.\n","Found 2625 images belonging to 525 classes.\n","Found 2625 images belonging to 525 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(rescale = 1./255)\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","valid_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","train_dir = dataset+\"\\\\train\"\n","test_dir = dataset+\"\\\\test\"\n","val_dir = dataset+\"\\\\valid\"\n","\n","\n","# data transfer from directories to batches\n","train_data = train_datagen.flow_from_directory(directory = train_dir,\n","                                               batch_size= 32,\n","                                               target_size= (224,224),\n","                                               class_mode = \"categorical\")\n","\n","test_data = test_datagen.flow_from_directory(directory = test_dir,\n","                                               batch_size = 32,\n","                                               target_size = (224,224),\n","                                               class_mode = \"categorical\")\n","\n","val_data = valid_datagen.flow_from_directory(directory = val_dir,\n","                                               batch_size = 32,\n","                                               target_size = (224,224),\n","                                               class_mode = \"categorical\")"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","model.compile(loss='categorical_crossentropy',\n","               optimizer='adam',\n","               metrics=['accuracy'])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Skip to model.load_weights if weights already present"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\divij\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 324ms/step - accuracy: 0.0280 - loss: 5.7542 - val_accuracy: 0.2094 - val_loss: 4.0535\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x2152db16890>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model\n","model.fit(train_data,\n","           steps_per_epoch = len(train_data),\n","           epochs=1,\n","           batch_size=16,\n","           validation_data =val_data,\n","           validation_steps = int(0.25*len(val_data)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the model\n","# model.save('cnn_model.h5')\n","# model.save_weights('cnn.weights.h5')"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Load saved weights (model.load_weights)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Assuming same model architecture is defined and compiled\n","model.load_weights('cnn.weights.h5')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m2645/2645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 74ms/step - accuracy: 0.9814 - loss: 0.1448\n","Train Accuracy: 98.13%\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.4587 - loss: 2.7969\n","Test Accuracy: 47.77%\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.4666 - loss: 3.0304\n","Val Accuracy: 47.16%\n"]}],"source":["# Evaluate the model on the test set\n","train_loss, train_acc = model.evaluate(train_data)\n","print(f'Train Accuracy: {train_acc*100:.2f}%')\n","\n","# Evaluate the model on the test set\n","test_loss, test_acc = model.evaluate(test_data)\n","print(f'Test Accuracy: {test_acc*100:.2f}%')\n","\n","# Evaluate on validation set\n","val_loss, val_accuracy = model.evaluate(val_data)\n","print(f'Val Accuracy: {val_accuracy*100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","#Initialize empty lists to hold predictions and true labels\n","all_preds = []\n","all_true_labels = []\n","\n","print(\"len Test\", len(test_data))\n","\n","#Manually iterate over the test generator\n","for i in range(len(test_data)):\n","    X_batch, y_batch = test_data[i]\n","    preds = model.predict_on_batch(X_batch)\n","    #print(\"dims\", preds.shape)\n","    # Store batch predictions and labels\n","    all_preds.extend(np.argmax(preds, axis=1))\n","    all_true_labels.extend(np.argmax(y_batch, axis=1))\n","\n","#Convert lists to arrays for evaluation\n","all_preds = np.array(all_preds)\n","print(\"all_preds\",all_preds)\n","all_true_labels = np.array(all_true_labels)\n","print(\"all_true_labels\", all_true_labels)\n","\n","#Print the evaluation report\n","print(classification_report(all_true_labels, all_preds))"]},{"cell_type":"markdown","metadata":{},"source":["## Gradcam"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting GradCam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n","# Load saved weights if necessary\n","model.load_weights('cnn.weights.h5')\n","\n","# Example usage of Grad-CAM with a sample image\n","def apply_gradcam_to_image(img_path, model, last_conv_layer_name):\n","    # Load and preprocess the image\n","    img = load_img(img_path, target_size=(224, 224))\n","    img_array = img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = img_array / 255.0  # Normalize the image\n","\n","    # Generate Grad-CAM heatmap\n","    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","\n","    # Display the Grad-CAM overlay on the image\n","    display_gradcam(img_array, heatmap)\n","\n","def display_gradcam(img, heatmap, alpha=0.005):\n","    # Convert the heatmap to RGB\n","    heatmap = np.uint8(255 * heatmap)\n","    jet = cm.get_cmap(\"jet\")\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","    jet_heatmap = array_to_img(jet_heatmap)\n","    # Make sure to match the dimensions of the original image\n","    jet_heatmap = jet_heatmap.resize((img.shape[2], img.shape[1]))\n","    jet_heatmap = img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on the original image\n","    img_squeezed = np.squeeze(img)  # Remove batch dimension\n","    superimposed_img = jet_heatmap * alpha + img_squeezed * \\\n","        (1 - alpha)  # Apply the heatmap overlay\n","    superimposed_img = array_to_img(superimposed_img)  # Convert to an image\n","\n","    # Display images\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(array_to_img(img_squeezed))  # Display the original image\n","    plt.axis('off')\n","    plt.title('Original Image')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(superimposed_img)\n","    plt.axis('off')\n","    plt.title('Grad-CAM Heatmap Overlay')\n","    plt.show()\n","# Specify an image path and layer name to visualize\n","img_path = '1.jpg'\n","layer_name = 'conv2d_2'  # Example: Use the name of one of your convolutional layers\n","\n","# Apply Grad-CAM to the specified image using your model\n","apply_gradcam_to_image(img_path, model, layer_name)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Estimated Validation Set Length: 82\n","Batch 1 Prediction shape: (32, 525)\n","Batch 2 Prediction shape: (32, 525)\n","Batch 3 Prediction shape: (32, 525)\n","Batch 4 Prediction shape: (32, 525)\n","Batch 5 Prediction shape: (32, 525)\n","Batch 6 Prediction shape: (32, 525)\n","Batch 7 Prediction shape: (32, 525)\n","Batch 8 Prediction shape: (32, 525)\n","Batch 9 Prediction shape: (32, 525)\n","Batch 10 Prediction shape: (32, 525)\n","Batch 11 Prediction shape: (32, 525)\n","Batch 12 Prediction shape: (32, 525)\n","Batch 13 Prediction shape: (32, 525)\n","Batch 14 Prediction shape: (32, 525)\n","Batch 15 Prediction shape: (32, 525)\n","Batch 16 Prediction shape: (32, 525)\n","Batch 17 Prediction shape: (32, 525)\n","Batch 18 Prediction shape: (32, 525)\n","Batch 19 Prediction shape: (32, 525)\n","Batch 20 Prediction shape: (32, 525)\n","Batch 21 Prediction shape: (32, 525)\n","Batch 22 Prediction shape: (32, 525)\n","Batch 23 Prediction shape: (32, 525)\n","Batch 24 Prediction shape: (32, 525)\n","Batch 25 Prediction shape: (32, 525)\n","Batch 26 Prediction shape: (32, 525)\n","Batch 27 Prediction shape: (32, 525)\n","Batch 28 Prediction shape: (32, 525)\n","Batch 29 Prediction shape: (32, 525)\n","Batch 30 Prediction shape: (32, 525)\n","Batch 31 Prediction shape: (32, 525)\n","Batch 32 Prediction shape: (32, 525)\n","Batch 33 Prediction shape: (32, 525)\n","Batch 34 Prediction shape: (32, 525)\n","Batch 35 Prediction shape: (32, 525)\n","Batch 36 Prediction shape: (32, 525)\n","Batch 37 Prediction shape: (32, 525)\n","Batch 38 Prediction shape: (32, 525)\n","Batch 39 Prediction shape: (32, 525)\n","Batch 40 Prediction shape: (32, 525)\n","Batch 41 Prediction shape: (32, 525)\n","Batch 42 Prediction shape: (32, 525)\n","Batch 43 Prediction shape: (32, 525)\n","Batch 44 Prediction shape: (32, 525)\n","Batch 45 Prediction shape: (32, 525)\n","Batch 46 Prediction shape: (32, 525)\n","Batch 47 Prediction shape: (32, 525)\n","Batch 48 Prediction shape: (32, 525)\n","Batch 49 Prediction shape: (32, 525)\n","Batch 50 Prediction shape: (32, 525)\n","Batch 51 Prediction shape: (32, 525)\n","Batch 52 Prediction shape: (32, 525)\n","Batch 53 Prediction shape: (32, 525)\n","Batch 54 Prediction shape: (32, 525)\n","Batch 55 Prediction shape: (32, 525)\n","Batch 56 Prediction shape: (32, 525)\n","Batch 57 Prediction shape: (32, 525)\n","Batch 58 Prediction shape: (32, 525)\n","Batch 59 Prediction shape: (32, 525)\n","Batch 60 Prediction shape: (32, 525)\n","Batch 61 Prediction shape: (32, 525)\n","Batch 62 Prediction shape: (32, 525)\n","Batch 63 Prediction shape: (32, 525)\n","Batch 64 Prediction shape: (32, 525)\n","Batch 65 Prediction shape: (32, 525)\n","Batch 66 Prediction shape: (32, 525)\n","Batch 67 Prediction shape: (32, 525)\n","Batch 68 Prediction shape: (32, 525)\n","Batch 69 Prediction shape: (32, 525)\n","Batch 70 Prediction shape: (32, 525)\n","Batch 71 Prediction shape: (32, 525)\n","Batch 72 Prediction shape: (32, 525)\n","Batch 73 Prediction shape: (32, 525)\n","Batch 74 Prediction shape: (32, 525)\n","Batch 75 Prediction shape: (32, 525)\n","Batch 76 Prediction shape: (32, 525)\n","Batch 77 Prediction shape: (32, 525)\n","Batch 78 Prediction shape: (32, 525)\n","Batch 79 Prediction shape: (32, 525)\n","Batch 80 Prediction shape: (32, 525)\n","Batch 81 Prediction shape: (32, 525)\n","Batch 82 Prediction shape: (32, 525)\n","All Predictions: [200 489   6 ... 331 168 515]\n","All True Labels: [200 481   6 ... 256 168 281]\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         5\n","           1       0.20      0.20      0.20         5\n","           2       0.00      0.00      0.00         5\n","           3       0.50      0.20      0.29         5\n","           4       0.40      0.40      0.40         5\n","           5       0.50      0.20      0.29         5\n","           6       1.00      0.60      0.75         5\n","           7       0.10      0.20      0.13         5\n","           8       0.33      0.20      0.25         5\n","           9       0.00      0.00      0.00         5\n","          10       0.25      0.20      0.22         5\n","          11       1.00      0.20      0.33         5\n","          12       0.43      0.60      0.50         5\n","          13       0.40      0.40      0.40         5\n","          14       0.29      0.40      0.33         5\n","          15       0.00      0.00      0.00         5\n","          16       1.00      0.20      0.33         5\n","          17       1.00      0.20      0.33         5\n","          18       0.56      1.00      0.71         5\n","          19       0.75      0.60      0.67         5\n","          20       0.00      0.00      0.00         5\n","          21       0.18      0.40      0.25         5\n","          22       1.00      0.20      0.33         5\n","          23       0.40      0.40      0.40         5\n","          24       0.00      0.00      0.00         5\n","          25       0.33      0.40      0.36         5\n","          26       0.67      0.80      0.73         5\n","          27       0.50      0.20      0.29         5\n","          28       0.25      0.20      0.22         5\n","          29       0.33      0.20      0.25         5\n","          30       0.29      0.40      0.33         5\n","          31       0.50      0.20      0.29         5\n","          32       0.00      0.00      0.00         5\n","          33       0.33      0.60      0.43         5\n","          34       0.50      0.20      0.29         5\n","          35       0.33      0.40      0.36         5\n","          36       0.83      1.00      0.91         5\n","          37       1.00      0.20      0.33         5\n","          38       0.33      0.40      0.36         5\n","          39       0.60      0.60      0.60         5\n","          40       0.38      0.60      0.46         5\n","          41       0.67      0.80      0.73         5\n","          42       0.29      0.40      0.33         5\n","          43       0.12      0.20      0.15         5\n","          44       0.00      0.00      0.00         5\n","          45       0.40      0.40      0.40         5\n","          46       1.00      0.40      0.57         5\n","          47       0.00      0.00      0.00         5\n","          48       0.71      1.00      0.83         5\n","          49       0.50      0.40      0.44         5\n","          50       0.67      0.40      0.50         5\n","          51       0.67      0.80      0.73         5\n","          52       0.50      0.40      0.44         5\n","          53       0.00      0.00      0.00         5\n","          54       0.00      0.00      0.00         5\n","          55       0.62      1.00      0.77         5\n","          56       0.40      0.40      0.40         5\n","          57       0.50      0.60      0.55         5\n","          58       0.75      0.60      0.67         5\n","          59       0.50      0.80      0.62         5\n","          60       0.80      0.80      0.80         5\n","          61       1.00      0.40      0.57         5\n","          62       0.83      1.00      0.91         5\n","          63       0.40      0.40      0.40         5\n","          64       0.60      0.60      0.60         5\n","          65       0.00      0.00      0.00         5\n","          66       0.50      0.20      0.29         5\n","          67       0.33      0.40      0.36         5\n","          68       0.50      0.60      0.55         5\n","          69       0.75      0.60      0.67         5\n","          70       0.00      0.00      0.00         5\n","          71       0.50      0.60      0.55         5\n","          72       0.67      0.40      0.50         5\n","          73       1.00      1.00      1.00         5\n","          74       0.50      0.80      0.62         5\n","          75       1.00      0.60      0.75         5\n","          76       0.00      0.00      0.00         5\n","          77       0.50      0.40      0.44         5\n","          78       0.14      0.20      0.17         5\n","          79       0.75      0.60      0.67         5\n","          80       0.50      0.60      0.55         5\n","          81       0.50      0.40      0.44         5\n","          82       0.60      0.60      0.60         5\n","          83       0.50      0.40      0.44         5\n","          84       0.56      1.00      0.71         5\n","          85       0.50      0.20      0.29         5\n","          86       0.00      0.00      0.00         5\n","          87       0.67      0.40      0.50         5\n","          88       0.25      0.20      0.22         5\n","          89       0.80      0.80      0.80         5\n","          90       0.75      0.60      0.67         5\n","          91       0.50      0.60      0.55         5\n","          92       0.60      0.60      0.60         5\n","          93       0.43      0.60      0.50         5\n","          94       0.80      0.80      0.80         5\n","          95       0.56      1.00      0.71         5\n","          96       0.27      0.60      0.38         5\n","          97       0.33      0.20      0.25         5\n","          98       0.33      0.40      0.36         5\n","          99       0.50      0.20      0.29         5\n","         100       0.67      0.40      0.50         5\n","         101       0.14      0.20      0.17         5\n","         102       1.00      0.40      0.57         5\n","         103       0.33      0.20      0.25         5\n","         104       0.50      0.40      0.44         5\n","         105       1.00      0.60      0.75         5\n","         106       0.40      0.40      0.40         5\n","         107       0.75      0.60      0.67         5\n","         108       0.33      0.20      0.25         5\n","         109       0.50      0.20      0.29         5\n","         110       0.60      0.60      0.60         5\n","         111       0.00      0.00      0.00         5\n","         112       0.33      0.20      0.25         5\n","         113       0.11      0.20      0.14         5\n","         114       1.00      0.80      0.89         5\n","         115       0.67      0.80      0.73         5\n","         116       0.62      1.00      0.77         5\n","         117       0.50      0.20      0.29         5\n","         118       0.50      0.20      0.29         5\n","         119       0.33      0.20      0.25         5\n","         120       0.33      0.60      0.43         5\n","         121       0.20      0.40      0.27         5\n","         122       0.00      0.00      0.00         5\n","         123       0.71      1.00      0.83         5\n","         124       0.83      1.00      0.91         5\n","         125       0.10      0.20      0.13         5\n","         126       1.00      0.60      0.75         5\n","         127       1.00      0.40      0.57         5\n","         128       0.56      1.00      0.71         5\n","         129       1.00      0.40      0.57         5\n","         130       0.44      0.80      0.57         5\n","         131       0.56      1.00      0.71         5\n","         132       0.75      0.60      0.67         5\n","         133       0.67      0.40      0.50         5\n","         134       0.42      1.00      0.59         5\n","         135       0.00      0.00      0.00         5\n","         136       0.40      0.40      0.40         5\n","         137       0.67      0.40      0.50         5\n","         138       0.20      0.20      0.20         5\n","         139       0.33      0.60      0.43         5\n","         140       1.00      0.40      0.57         5\n","         141       0.67      0.40      0.50         5\n","         142       0.33      0.20      0.25         5\n","         143       0.09      0.20      0.12         5\n","         144       0.40      0.80      0.53         5\n","         145       0.62      1.00      0.77         5\n","         146       1.00      1.00      1.00         5\n","         147       0.43      0.60      0.50         5\n","         148       0.44      0.80      0.57         5\n","         149       0.50      0.40      0.44         5\n","         150       0.50      0.60      0.55         5\n","         151       1.00      0.80      0.89         5\n","         152       0.60      0.60      0.60         5\n","         153       0.25      0.40      0.31         5\n","         154       0.50      1.00      0.67         5\n","         155       0.50      0.40      0.44         5\n","         156       0.20      0.20      0.20         5\n","         157       0.50      0.80      0.62         5\n","         158       0.33      0.20      0.25         5\n","         159       0.50      0.40      0.44         5\n","         160       0.67      0.80      0.73         5\n","         161       0.67      0.40      0.50         5\n","         162       0.40      0.40      0.40         5\n","         163       0.50      0.20      0.29         5\n","         164       0.71      1.00      0.83         5\n","         165       0.83      1.00      0.91         5\n","         166       1.00      0.20      0.33         5\n","         167       0.57      0.80      0.67         5\n","         168       0.57      0.80      0.67         5\n","         169       0.50      0.60      0.55         5\n","         170       0.20      0.20      0.20         5\n","         171       1.00      0.40      0.57         5\n","         172       1.00      0.80      0.89         5\n","         173       0.50      0.20      0.29         5\n","         174       0.80      0.80      0.80         5\n","         175       0.33      0.40      0.36         5\n","         176       0.50      0.20      0.29         5\n","         177       0.22      0.40      0.29         5\n","         178       0.50      0.40      0.44         5\n","         179       0.50      0.60      0.55         5\n","         180       0.00      0.00      0.00         5\n","         181       0.83      1.00      0.91         5\n","         182       0.71      1.00      0.83         5\n","         183       0.67      0.80      0.73         5\n","         184       0.50      0.60      0.55         5\n","         185       0.20      0.20      0.20         5\n","         186       0.60      0.60      0.60         5\n","         187       0.33      0.20      0.25         5\n","         188       0.50      0.40      0.44         5\n","         189       0.33      0.20      0.25         5\n","         190       0.60      0.60      0.60         5\n","         191       0.25      0.20      0.22         5\n","         192       0.33      0.40      0.36         5\n","         193       0.50      0.60      0.55         5\n","         194       0.67      0.40      0.50         5\n","         195       0.60      0.60      0.60         5\n","         196       0.20      0.20      0.20         5\n","         197       0.83      1.00      0.91         5\n","         198       0.38      0.60      0.46         5\n","         199       1.00      0.80      0.89         5\n","         200       0.25      0.60      0.35         5\n","         201       0.75      0.60      0.67         5\n","         202       0.50      0.60      0.55         5\n","         203       0.33      0.40      0.36         5\n","         204       0.00      0.00      0.00         5\n","         205       0.33      0.40      0.36         5\n","         206       1.00      0.60      0.75         5\n","         207       0.60      0.60      0.60         5\n","         208       0.57      0.80      0.67         5\n","         209       0.50      0.20      0.29         5\n","         210       1.00      0.80      0.89         5\n","         211       0.50      0.60      0.55         5\n","         212       0.60      0.60      0.60         5\n","         213       0.38      0.60      0.46         5\n","         214       0.80      0.80      0.80         5\n","         215       0.50      0.40      0.44         5\n","         216       0.29      0.40      0.33         5\n","         217       1.00      0.20      0.33         5\n","         218       0.67      0.80      0.73         5\n","         219       0.50      0.60      0.55         5\n","         220       0.60      0.60      0.60         5\n","         221       0.50      0.20      0.29         5\n","         222       0.50      0.20      0.29         5\n","         223       0.00      0.00      0.00         5\n","         224       0.00      0.00      0.00         5\n","         225       0.67      0.80      0.73         5\n","         226       0.00      0.00      0.00         5\n","         227       0.57      0.80      0.67         5\n","         228       0.71      1.00      0.83         5\n","         229       0.40      0.80      0.53         5\n","         230       0.50      0.60      0.55         5\n","         231       0.00      0.00      0.00         5\n","         232       0.14      0.20      0.17         5\n","         233       1.00      1.00      1.00         5\n","         234       0.33      0.20      0.25         5\n","         235       0.50      0.60      0.55         5\n","         236       0.33      0.40      0.36         5\n","         237       0.60      0.60      0.60         5\n","         238       0.50      0.60      0.55         5\n","         239       0.80      0.80      0.80         5\n","         240       0.33      0.60      0.43         5\n","         241       0.44      0.80      0.57         5\n","         242       0.57      0.80      0.67         5\n","         243       0.33      0.60      0.43         5\n","         244       0.36      0.80      0.50         5\n","         245       0.50      0.60      0.55         5\n","         246       0.67      0.80      0.73         5\n","         247       0.80      0.80      0.80         5\n","         248       1.00      0.80      0.89         5\n","         249       0.50      0.60      0.55         5\n","         250       0.33      0.60      0.43         5\n","         251       0.25      0.20      0.22         5\n","         252       0.50      0.20      0.29         5\n","         253       0.60      0.60      0.60         5\n","         254       1.00      0.60      0.75         5\n","         255       0.60      0.60      0.60         5\n","         256       0.00      0.00      0.00         5\n","         257       0.33      0.20      0.25         5\n","         258       0.33      0.40      0.36         5\n","         259       0.33      0.40      0.36         5\n","         260       0.40      0.80      0.53         5\n","         261       0.29      0.40      0.33         5\n","         262       0.67      0.80      0.73         5\n","         263       0.50      1.00      0.67         5\n","         264       0.57      0.80      0.67         5\n","         265       0.33      0.40      0.36         5\n","         266       0.00      0.00      0.00         5\n","         267       0.50      0.40      0.44         5\n","         268       0.20      0.50      0.29         4\n","         269       1.00      0.80      0.89         5\n","         270       0.00      0.00      0.00         5\n","         271       0.50      0.40      0.44         5\n","         272       1.00      1.00      1.00         5\n","         273       1.00      0.60      0.75         5\n","         274       0.14      0.20      0.17         5\n","         275       0.50      0.60      0.55         5\n","         276       1.00      1.00      1.00         5\n","         277       0.75      0.60      0.67         5\n","         278       0.20      0.20      0.20         5\n","         279       0.75      0.60      0.67         5\n","         280       0.67      0.80      0.73         5\n","         281       0.50      0.60      0.55         5\n","         282       0.12      0.20      0.15         5\n","         283       0.33      0.80      0.47         5\n","         284       0.25      0.20      0.22         5\n","         285       0.25      0.20      0.22         5\n","         286       1.00      1.00      1.00         5\n","         287       0.29      0.40      0.33         5\n","         288       1.00      0.60      0.75         5\n","         289       0.00      0.00      0.00         5\n","         290       0.83      1.00      0.91         5\n","         291       0.11      0.20      0.14         5\n","         292       1.00      0.40      0.57         5\n","         293       1.00      1.00      1.00         5\n","         294       0.38      0.60      0.46         5\n","         295       0.80      0.80      0.80         5\n","         296       0.00      0.00      0.00         5\n","         297       0.12      0.20      0.15         5\n","         298       0.67      0.80      0.73         5\n","         299       0.67      0.80      0.73         5\n","         300       0.50      0.60      0.55         5\n","         301       0.33      0.20      0.25         5\n","         302       0.40      0.40      0.40         5\n","         303       0.33      0.60      0.43         5\n","         304       0.33      0.40      0.36         5\n","         305       1.00      0.60      0.75         5\n","         306       0.60      0.60      0.60         5\n","         307       0.43      0.60      0.50         5\n","         308       0.33      0.20      0.25         5\n","         309       0.67      0.40      0.50         5\n","         310       0.33      0.20      0.25         5\n","         311       0.40      0.40      0.40         5\n","         312       0.80      0.80      0.80         5\n","         313       0.80      0.80      0.80         5\n","         314       1.00      0.60      0.75         5\n","         315       0.17      0.20      0.18         5\n","         316       0.43      0.60      0.50         5\n","         317       0.50      0.60      0.55         5\n","         318       0.33      0.20      0.25         5\n","         319       0.67      0.40      0.50         5\n","         320       0.20      0.20      0.20         5\n","         321       0.50      0.40      0.44         5\n","         322       0.50      0.40      0.44         5\n","         323       0.40      0.40      0.40         5\n","         324       0.50      0.20      0.29         5\n","         325       0.60      0.60      0.60         5\n","         326       1.00      0.60      0.75         5\n","         327       1.00      0.20      0.33         5\n","         328       0.25      0.20      0.22         5\n","         329       0.50      0.60      0.55         5\n","         330       0.38      0.60      0.46         5\n","         331       0.00      0.00      0.00         5\n","         332       0.57      0.80      0.67         5\n","         333       0.50      0.60      0.55         5\n","         334       0.50      0.20      0.29         5\n","         335       0.00      0.00      0.00         5\n","         336       0.60      0.60      0.60         5\n","         337       0.50      0.40      0.44         5\n","         338       0.00      0.00      0.00         5\n","         339       0.50      0.20      0.29         5\n","         340       1.00      0.60      0.75         5\n","         341       0.33      0.20      0.25         5\n","         342       0.33      0.20      0.25         5\n","         343       0.44      0.80      0.57         5\n","         344       0.33      0.20      0.25         5\n","         345       0.00      0.00      0.00         5\n","         346       0.00      0.00      0.00         5\n","         347       0.40      0.40      0.40         5\n","         348       0.25      0.20      0.22         5\n","         349       0.00      0.00      0.00         5\n","         350       0.00      0.00      0.00         5\n","         351       0.60      0.60      0.60         5\n","         352       0.67      0.40      0.50         5\n","         353       0.25      0.20      0.22         5\n","         354       0.25      0.20      0.22         5\n","         355       0.67      0.40      0.50         5\n","         356       0.40      0.80      0.53         5\n","         357       0.00      0.00      0.00         5\n","         358       0.00      0.00      0.00         5\n","         359       0.00      0.00      0.00         5\n","         360       0.83      1.00      0.91         5\n","         361       0.20      0.20      0.20         5\n","         362       0.33      0.40      0.36         5\n","         363       1.00      1.00      1.00         5\n","         364       0.00      0.00      0.00         5\n","         365       1.00      0.40      0.57         5\n","         366       0.67      0.40      0.50         5\n","         367       1.00      0.80      0.89         5\n","         368       1.00      0.60      0.75         5\n","         369       0.71      1.00      0.83         5\n","         370       1.00      0.60      0.75         5\n","         371       0.11      0.20      0.14         5\n","         372       0.50      0.20      0.29         5\n","         373       0.50      0.40      0.44         5\n","         374       0.25      0.40      0.31         5\n","         375       0.67      0.80      0.73         5\n","         376       0.62      1.00      0.77         5\n","         377       0.50      0.40      0.44         5\n","         378       0.00      0.00      0.00         5\n","         379       0.60      0.60      0.60         5\n","         380       0.67      0.80      0.73         5\n","         381       0.50      0.60      0.55         5\n","         382       0.60      0.60      0.60         5\n","         383       0.43      0.60      0.50         5\n","         384       0.33      0.20      0.25         5\n","         385       1.00      0.20      0.33         5\n","         386       0.00      0.00      0.00         5\n","         387       1.00      1.00      1.00         5\n","         388       0.29      0.40      0.33         5\n","         389       0.00      0.00      0.00         5\n","         390       0.71      1.00      0.83         5\n","         391       0.60      0.60      0.60         5\n","         392       0.67      0.40      0.50         5\n","         393       0.50      0.60      0.55         5\n","         394       0.50      0.60      0.55         5\n","         395       0.50      0.40      0.44         5\n","         396       0.50      0.40      0.44         5\n","         397       0.60      0.60      0.60         5\n","         398       0.33      0.60      0.43         5\n","         399       0.50      0.60      0.55         5\n","         400       0.50      0.80      0.62         5\n","         401       0.80      0.80      0.80         5\n","         402       0.83      1.00      0.91         5\n","         403       0.33      0.40      0.36         5\n","         404       0.22      0.40      0.29         5\n","         405       0.33      0.20      0.25         5\n","         406       1.00      0.40      0.57         5\n","         407       0.50      0.80      0.62         5\n","         408       1.00      0.80      0.89         5\n","         409       0.50      0.40      0.44         5\n","         410       1.00      0.40      0.57         5\n","         411       0.60      0.60      0.60         5\n","         412       0.50      0.80      0.62         5\n","         413       1.00      0.80      0.89         5\n","         414       0.14      0.20      0.17         5\n","         415       0.25      0.20      0.22         5\n","         416       0.50      0.40      0.44         5\n","         417       0.33      0.20      0.25         5\n","         418       0.67      0.40      0.50         5\n","         419       1.00      1.00      1.00         5\n","         420       1.00      0.80      0.89         5\n","         421       0.43      0.60      0.50         5\n","         422       0.50      0.40      0.44         5\n","         423       0.25      0.20      0.22         5\n","         424       0.75      0.60      0.67         5\n","         425       0.38      0.60      0.46         5\n","         426       0.29      0.40      0.33         5\n","         427       0.22      0.40      0.29         5\n","         428       0.56      1.00      0.71         5\n","         429       0.00      0.00      0.00         5\n","         430       0.57      0.80      0.67         5\n","         431       0.00      0.00      0.00         5\n","         432       0.71      1.00      0.83         5\n","         433       0.45      1.00      0.62         5\n","         434       0.50      0.40      0.44         5\n","         435       1.00      0.40      0.57         5\n","         436       0.75      0.60      0.67         5\n","         437       0.00      0.00      0.00         5\n","         438       0.40      0.40      0.40         5\n","         439       0.80      0.80      0.80         5\n","         440       0.18      0.40      0.25         5\n","         441       0.40      0.40      0.40         5\n","         442       0.60      0.60      0.60         5\n","         443       0.38      0.60      0.46         5\n","         444       0.50      0.40      0.44         5\n","         445       0.30      0.60      0.40         5\n","         446       0.25      0.20      0.22         5\n","         447       0.00      0.00      0.00         5\n","         448       0.60      0.60      0.60         5\n","         449       0.50      0.20      0.29         5\n","         450       0.40      0.40      0.40         5\n","         451       0.33      0.20      0.25         5\n","         452       0.00      0.00      0.00         5\n","         453       0.50      0.60      0.55         5\n","         454       0.17      0.40      0.24         5\n","         455       0.60      0.60      0.60         5\n","         456       1.00      0.40      0.57         5\n","         457       0.75      0.60      0.67         5\n","         458       0.40      0.40      0.40         5\n","         459       0.40      0.40      0.40         5\n","         460       0.67      0.40      0.50         5\n","         461       0.50      0.40      0.44         5\n","         462       1.00      0.60      0.75         5\n","         463       0.00      0.00      0.00         5\n","         464       0.30      0.60      0.40         5\n","         465       0.25      0.20      0.22         5\n","         466       0.40      0.40      0.40         5\n","         467       0.67      0.80      0.73         5\n","         468       0.00      0.00      0.00         5\n","         469       0.00      0.00      0.00         5\n","         470       0.71      1.00      0.83         5\n","         471       0.75      0.60      0.67         5\n","         472       0.20      0.20      0.20         5\n","         473       0.00      0.00      0.00         5\n","         474       0.67      0.80      0.73         5\n","         475       0.33      0.20      0.25         5\n","         476       0.75      0.60      0.67         5\n","         477       0.00      0.00      0.00         5\n","         478       1.00      0.40      0.57         5\n","         479       0.40      0.40      0.40         5\n","         480       0.60      0.60      0.60         5\n","         481       0.33      0.60      0.43         5\n","         482       0.44      0.80      0.57         5\n","         483       0.00      0.00      0.00         5\n","         484       0.20      0.20      0.20         5\n","         485       0.50      0.20      0.29         5\n","         486       0.00      0.00      0.00         5\n","         487       0.57      0.80      0.67         5\n","         488       1.00      1.00      1.00         5\n","         489       0.67      0.80      0.73         5\n","         490       0.00      0.00      0.00         5\n","         491       0.60      0.60      0.60         5\n","         492       0.67      0.40      0.50         5\n","         493       0.44      0.80      0.57         5\n","         494       0.50      0.40      0.44         5\n","         495       0.75      0.60      0.67         5\n","         496       0.67      0.40      0.50         5\n","         497       0.33      0.60      0.43         5\n","         498       0.71      1.00      0.83         5\n","         499       0.60      0.60      0.60         5\n","         500       0.71      1.00      0.83         5\n","         501       0.57      0.80      0.67         5\n","         502       0.60      0.60      0.60         5\n","         503       0.43      0.60      0.50         5\n","         504       0.60      0.60      0.60         5\n","         505       0.50      0.40      0.44         5\n","         506       0.33      0.40      0.36         5\n","         507       1.00      0.20      0.33         5\n","         508       0.50      0.20      0.29         5\n","         509       0.43      0.60      0.50         5\n","         510       0.25      0.20      0.22         5\n","         511       0.00      0.00      0.00         5\n","         512       0.56      1.00      0.71         5\n","         513       1.00      0.80      0.89         5\n","         514       1.00      0.60      0.75         5\n","         515       0.83      1.00      0.91         5\n","         516       0.57      0.80      0.67         5\n","         517       0.00      0.00      0.00         5\n","         518       1.00      0.60      0.75         5\n","         519       0.00      0.00      0.00         5\n","         520       0.20      0.20      0.20         5\n","         521       0.25      0.20      0.22         5\n","         522       0.80      0.80      0.80         5\n","         523       1.00      0.60      0.75         5\n","         524       0.11      0.20      0.14         5\n","\n","    accuracy                           0.47      2624\n","   macro avg       0.49      0.47      0.46      2624\n","weighted avg       0.49      0.47      0.46      2624\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\divij\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\divij\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\divij\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","# Initialize empty lists to hold predictions and true labels\n","all_preds = []\n","all_true_labels = []\n","\n","# Estimate the length of the validation set\n","validation_samples = len(val_data.filenames)\n","batch_size = val_data.batch_size\n","estimated_length = validation_samples // batch_size\n","print(\"Estimated Validation Set Length:\", estimated_length)\n","\n","# Manually iterate over the estimated length of the validation set\n","for i in range(estimated_length):\n","    X_batch, y_batch = next(val_data)\n","    preds = model.predict_on_batch(X_batch)\n","    # Print dimensions of predictions and batch number\n","    print(\"Batch\", i+1, \"Prediction shape:\", preds.shape)\n","    # Store batch predictions and labels\n","    all_preds.extend(np.argmax(preds, axis=1))\n","    all_true_labels.extend(np.argmax(y_batch, axis=1))\n","\n","# Convert lists to arrays for evaluation\n","all_preds = np.array(all_preds)\n","print(\"All Predictions:\", all_preds)\n","all_true_labels = np.array(all_true_labels)\n","print(\"All True Labels:\", all_true_labels)\n","\n","# Print the evaluation report\n","print(classification_report(all_true_labels, all_preds))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":534640,"sourceId":5468571,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
